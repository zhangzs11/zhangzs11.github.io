<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>GraphicsSystem-Deferred Rendering | Canned Pixels</title><meta name="author" content="Zishuai Zhang,zhangzs2023@163.com"><meta name="copyright" content="Zishuai Zhang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="Deferred Rendering: G-Buffer ConstructionThe first stage of deferred rendering involves constructing the G-Buffer, which stores essential pre-pixel data like normals, albedo, position, and specular pr">
<meta property="og:type" content="article">
<meta property="og:title" content="GraphicsSystem-Deferred Rendering">
<meta property="og:url" content="https://zhangzs11.github.io/2025/01/20/GraphicsSystem-DeferredRendering/index.html">
<meta property="og:site_name" content="Canned Pixels">
<meta property="og:description" content="Deferred Rendering: G-Buffer ConstructionThe first stage of deferred rendering involves constructing the G-Buffer, which stores essential pre-pixel data like normals, albedo, position, and specular pr">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhangzs11.github.io/img/MyAvatar.jpg">
<meta property="article:published_time" content="2025-01-20T21:05:08.640Z">
<meta property="article:modified_time" content="2025-02-02T23:30:05.675Z">
<meta property="article:author" content="Zishuai Zhang">
<meta property="article:tag" content="Computer Graphics, D3D, Game Engine Development">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhangzs11.github.io/img/MyAvatar.jpg"><link rel="shortcut icon" href="/img/MyAvatar.jpg"><link rel="canonical" href="https://zhangzs11.github.io/2025/01/20/GraphicsSystem-DeferredRendering/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'GraphicsSystem-Deferred Rendering',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background: linear-gradient(20deg, #b9fbc0, #98f5e1, #90dbf4, #cfbaf0);"></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/images/Funny/background_heart_emo.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Canned Pixels</span></a><a class="nav-page-title" href="/"><span class="site-name">GraphicsSystem-Deferred Rendering</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">GraphicsSystem-Deferred Rendering<a class="post-edit-link" href="null_posts/GraphicsSystem-DeferredRendering.md" title="Edit" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-01-20T21:05:08.640Z" title="Created 2025-01-20 14:05:08">2025-01-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-02-02T23:30:05.675Z" title="Updated 2025-02-02 16:30:05">2025-02-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Game-Engine/">Game Engine</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="Deferred-Rendering-G-Buffer-Construction"><a href="#Deferred-Rendering-G-Buffer-Construction" class="headerlink" title="Deferred Rendering: G-Buffer Construction"></a>Deferred Rendering: G-Buffer Construction</h1><p>The first stage of deferred rendering involves constructing the <strong>G-Buffer</strong>, which stores essential pre-pixel data like normals, albedo, position, and specular properties.</p>
<h2 id="Vertex-Shader"><a href="#Vertex-Shader" class="headerlink" title="Vertex Shader"></a>Vertex Shader</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">main</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    in <span class="type">const</span> float3 i_vertexPosition_local : POSITION,</span></span></span><br><span class="line"><span class="params"><span class="function">    in <span class="type">const</span> float2 i_vertexUV : TEXCOORD0,</span></span></span><br><span class="line"><span class="params"><span class="function">    in <span class="type">const</span> float3 i_vertexNormal : NORMAL,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span></span></span><br><span class="line"><span class="params"><span class="function">    out float4 o_vertexPosition_projected : SV_POSITION,</span></span></span><br><span class="line"><span class="params"><span class="function">    out float3 o_vertexPosition_view : POSITION,</span></span></span><br><span class="line"><span class="params"><span class="function">    out float2 o_vertexUV : TEXCOORD0,</span></span></span><br><span class="line"><span class="params"><span class="function">    out float3 o_vertexNormal_view : NORMAL</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    float4 vertexPosition_local = <span class="built_in">float4</span>(i_vertexPosition_local, <span class="number">1.0</span>);</span><br><span class="line">    float4 vertexPosition_world = <span class="built_in">mul</span>(g_transform_localToWorld, vertexPosition_local);</span><br><span class="line">    float4 vertexPosition_camera = <span class="built_in">mul</span>(g_transform_worldToCamera, vertexPosition_world);</span><br><span class="line"></span><br><span class="line">    o_vertexPosition_view = vertexPosition_camera.xyz;</span><br><span class="line">    o_vertexPosition_projected = <span class="built_in">mul</span>(g_transform_cameraToProjected, vertexPosition_camera);</span><br><span class="line"></span><br><span class="line">    float3 vertexNormal_world = <span class="built_in">mul</span>((float3x3)g_transform_localToWorld_Inv_Transpose, i_vertexNormal);</span><br><span class="line">    o_vertexNormal_view = <span class="built_in">mul</span>((float3x3)g_transform_worldToCamera, vertexNormal_world);</span><br><span class="line">    o_vertexUV = i_vertexUV;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Pixel-Shader"><a href="#Pixel-Shader" class="headerlink" title="Pixel Shader"></a>Pixel Shader</h2><p>The pixel shader take the interpolated data from the vertex shader and writes the <strong>G-Buffer</strong>, which consists of multiple render targets<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">GBuffer</span></span><br><span class="line">&#123;</span><br><span class="line">    float4 normal_specular : SV_Target0;  <span class="comment">// Encoded normal and specular data (R16G16B16A16_FLOAT)</span></span><br><span class="line">    float4 albedo : SV_Target1;           <span class="comment">// Diffuse albedo color (R8G8B8A8_UNORM)</span></span><br><span class="line">    float2 posZGrad : SV_Target2;         <span class="comment">// Depth gradients (R16G16_FLOAT)</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">main</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    in <span class="type">const</span> float4 i_fragmentPosition : SV_POSITION,</span></span></span><br><span class="line"><span class="params"><span class="function">    in <span class="type">const</span> float3 i_fragmentPosition_view : POSITION,</span></span></span><br><span class="line"><span class="params"><span class="function">    in <span class="type">const</span> float2 i_fragmentUV : TEXCOORD0,</span></span></span><br><span class="line"><span class="params"><span class="function">    in float3 i_fragmentNormal_view : NORMAL,</span></span></span><br><span class="line"><span class="params"><span class="function">    out GBuffer outputGBuffer</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    VertexPosHVNormalVTex inputGeometry;</span><br><span class="line">    inputGeometry.posH = i_fragmentPosition;</span><br><span class="line">    inputGeometry.posV = i_fragmentPosition_view;</span><br><span class="line">    inputGeometry.normalV = i_fragmentNormal_view;</span><br><span class="line">    inputGeometry.texCoord = i_fragmentUV;</span><br><span class="line"></span><br><span class="line">    SurfaceData surface = <span class="built_in">ComputeSurfaceDataFromGeometry</span>(inputGeometry);</span><br><span class="line"></span><br><span class="line">    outputGBuffer.normal_specular = <span class="built_in">float4</span>(<span class="built_in">EncodeSphereMap</span>(surface.normalV), surface.specularAmount, surface.specularPower);</span><br><span class="line">    outputGBuffer.albedo = surface.albedo;</span><br><span class="line">    outputGBuffer.posZGrad = <span class="built_in">float2</span>(<span class="built_in">ddx_coarse</span>(surface.posV.z), <span class="built_in">ddy_coarse</span>(surface.posV.z));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Surface-Data-Calculation"><a href="#Surface-Data-Calculation" class="headerlink" title="Surface Data Calculation"></a>Surface Data Calculation</h3><p>To populate the G-Buffer, we first calculate <strong>SurfaceData</strong> based on the input geometry:<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SurfaceData</span></span><br><span class="line">&#123;</span><br><span class="line">    float3 posV;</span><br><span class="line">    float3 posV_DX;</span><br><span class="line">    float3 posV_DY;</span><br><span class="line">    float3 normalV;</span><br><span class="line">    float4 albedo;</span><br><span class="line">    <span class="type">float</span> specularAmount;</span><br><span class="line">    <span class="type">float</span> specularPower;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">SurfaceData <span class="title">ComputeSurfaceDataFromGeometry</span><span class="params">(VertexPosHVNormalVTex input)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    SurfaceData surface;</span><br><span class="line">    surface.posV = input.posV;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Pixel position deltas in view space</span></span><br><span class="line">    surface.posV_DX = <span class="built_in">ddx_coarse</span>(surface.posV);</span><br><span class="line">    surface.posV_DY = <span class="built_in">ddy_coarse</span>(surface.posV);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Use face normal if needed, otherwise mesh normal</span></span><br><span class="line">    float3 faceNormal = <span class="built_in">ComputeFaceNormal</span>(input.posV);</span><br><span class="line">    surface.normalV = <span class="built_in">normalize</span>(g_FaceNormals ? faceNormal : input.normalV);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Sample texture for albedo</span></span><br><span class="line">    surface.albedo = g_DiffuseMap.<span class="built_in">Sample</span>(g_Sam, input.texCoord);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Specular properties (hardcoded for now)</span></span><br><span class="line">    surface.specularAmount = <span class="number">0.9f</span>;</span><br><span class="line">    surface.specularPower = <span class="number">25.0f</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> surface;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="Face-Normal-Calculation"><a href="#Face-Normal-Calculation" class="headerlink" title="Face Normal Calculation"></a>Face Normal Calculation</h4><p>If the mesh-provided normal is not used, face normals are calculated using cross products:<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">float3 <span class="title">ComputeFaceNormal</span><span class="params">(float3 pos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">cross</span>(<span class="built_in">ddy_coarse</span>(pos), <span class="built_in">ddx_coarse</span>(pos));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Normal-Encoding"><a href="#Normal-Encoding" class="headerlink" title="Normal Encoding"></a>Normal Encoding</h3><p>Normals are encoded using <strong>Sphere Map Transformation</strong>, which maps a 3D vector to 2D UV coordinates within [0, 1]. This method is efficient and compact.<br><strong>Encoding:</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">float2 <span class="title">EncodeSphereMap</span><span class="params">(float3 normal)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">normalize</span>(normal.xy) * <span class="built_in">sqrt</span>(-normal.z * <span class="number">0.5f</span> + <span class="number">0.5f</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="G-Buffer-Outputs"><a href="#G-Buffer-Outputs" class="headerlink" title="G-Buffer Outputs"></a>G-Buffer Outputs</h2><p>Each render target in the G-Buffer (and a depth buffer) stores specific information:<br><strong>1. normal_specular:</strong></p>
<ul>
<li>Encoded normals in two channels (using EncodeSphereMap)</li>
<li>Specular amount and power in the other two channels</li>
</ul>
<p><strong>2. albedo:</strong></p>
<ul>
<li>Diffuse albedo color from the texture</li>
</ul>
<p><strong>3. posZGrad:</strong></p>
<ul>
<li>Depth gradients calculated using coarse derivatives (<code>ddx_coarse</code>, <code>ddy_coarse</code>)</li>
</ul>
<p><strong>4. Depth buffer</strong></p>
<h1 id="Decoding-G-Buffer-for-Scene-Rendering"><a href="#Decoding-G-Buffer-for-Scene-Rendering" class="headerlink" title="Decoding G-Buffer for Scene Rendering"></a>Decoding G-Buffer for Scene Rendering</h1><p>After constructing the G-Buffer, the next step in deferred rendering is to decode the G-Buffer during scene rendering. This process involves retrieving essential pre-pixel data such as position, normal, and surface properties for shading calculations.</p>
<h2 id="Decoding-the-G-Buffer"><a href="#Decoding-the-G-Buffer" class="headerlink" title="Decoding the G-Buffer"></a>Decoding the G-Buffer</h2><p>The main goal is to reconstruct the following information for each pixel<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SurfaceData</span></span><br><span class="line">&#123;</span><br><span class="line">    float3 posV;            <span class="comment">// View-space position</span></span><br><span class="line">    float3 posV_DX;         <span class="comment">// View-space position gradient in X direction</span></span><br><span class="line">    float3 posV_DY;         <span class="comment">// View-space position gradient in Y direction</span></span><br><span class="line">    float3 normalV;         <span class="comment">// View-space normal</span></span><br><span class="line">    float4 albedo;          <span class="comment">// Albedo color</span></span><br><span class="line">    <span class="type">float</span> specularAmount;   <span class="comment">// Specular intensity</span></span><br><span class="line">    <span class="type">float</span> specularPower;    <span class="comment">// Specular exponent</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<h2 id="Decoding-Function"><a href="#Decoding-Function" class="headerlink" title="Decoding Function"></a>Decoding Function</h2><p>The G-Buffer is decoded using the following function<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Input</span></span><br><span class="line"><span class="comment">//======</span></span><br><span class="line">in <span class="type">const</span> float4 i_fragmentPosition : SV_POSITION,</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">SurfaceData surface = <span class="built_in">ComputeSurfaceDataFromGBufferSample</span>(<span class="built_in">uint2</span>(i_fragmentPosition.xy));</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function">SurfaceData <span class="title">ComputeSurfaceDataFromGBufferSample</span><span class="params">(uint2 posViewport)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    GBuffer rawData;</span><br><span class="line">    rawData.normal_specular = g_GBufferTextures_<span class="number">01.L</span>oad(<span class="built_in">int3</span>(posViewport.xy, <span class="number">0</span>)).xyzw;</span><br><span class="line">    rawData.albedo = g_GBufferTextures_<span class="number">02.L</span>oad(<span class="built_in">int3</span>(posViewport.xy, <span class="number">0</span>)).xyzw;</span><br><span class="line">    rawData.posZGrad = g_GBufferTextures_<span class="number">03.L</span>oad(<span class="built_in">int3</span>(posViewport.xy, <span class="number">0</span>)).xy;</span><br><span class="line">    <span class="type">float</span> zBuffer = g_GBufferTextures_<span class="number">04.L</span>oad(<span class="built_in">int3</span>(posViewport.xy, <span class="number">0</span>)).x;</span><br><span class="line"></span><br><span class="line">    float2 gbufferDim;</span><br><span class="line">    g_GBufferTextures_<span class="number">01.</span><span class="built_in">GetDimensions</span>(gbufferDim.x, gbufferDim.y);</span><br><span class="line"></span><br><span class="line">    float2 screenPixelOffset = <span class="built_in">float2</span>(<span class="number">2.0f</span>, <span class="number">-2.0f</span>) / gbufferDim;</span><br><span class="line">    float2 posNdc = (<span class="built_in">float2</span>(posViewport.xy) + <span class="number">0.5f</span>) * screenPixelOffset.xy + <span class="built_in">float2</span>(<span class="number">-1.0f</span>, <span class="number">1.0f</span>);</span><br><span class="line">    float2 posNdcX = posNdc + <span class="built_in">float2</span>(screenPixelOffset.x, <span class="number">0.0f</span>);</span><br><span class="line">    float2 posNdcY = posNdc + <span class="built_in">float2</span>(<span class="number">0.0f</span>, screenPixelOffset.y);</span><br><span class="line"></span><br><span class="line">    SurfaceData data;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> viewSpaceZ = g_transform_cameraToProjected._m23 / (-zBuffer - g_transform_cameraToProjected._m22); </span><br><span class="line"></span><br><span class="line">    data.posV = <span class="built_in">ComputePositionViewFromZ</span>(posNdc, viewSpaceZ);  </span><br><span class="line">    data.posV_DX = <span class="built_in">ComputePositionViewFromZ</span>(posNdcX, viewSpaceZ + rawData.posZGrad.x) - data.posV;</span><br><span class="line">    data.posV_DY = <span class="built_in">ComputePositionViewFromZ</span>(posNdcY, viewSpaceZ + rawData.posZGrad.y) - data.posV;</span><br><span class="line"></span><br><span class="line">    data.normalV = <span class="built_in">DecodeSphereMap</span>(rawData.normal_specular.xy);</span><br><span class="line">    data.albedo = rawData.albedo;</span><br><span class="line"></span><br><span class="line">    data.specularAmount = rawData.normal_specular.z;</span><br><span class="line">    data.specularPower = rawData.normal_specular.w;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Reconstructing-View-Space-Position"><a href="#Reconstructing-View-Space-Position" class="headerlink" title="Reconstructing View-Space Position"></a>Reconstructing View-Space Position</h3><p>The view-space position (<code>posV</code>) is reconstructed using <strong>the depth value</strong> (<code>zBuffer</code>) and <strong>screen-space coordinates</strong> (<code>posNdc</code>).</p>
<h4 id="1-Depth-to-View-Space-Conversion"><a href="#1-Depth-to-View-Space-Conversion" class="headerlink" title="1. Depth to View-Space Conversion :"></a>1. Depth to View-Space Conversion :</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> viewSpaceZ = g_transform_cameraToProjected._m23 / (-zBuffer - g_transform_cameraToProjected._m22);</span><br></pre></td></tr></table></figure>
<h4 id="2-Reconstructing-View-Space-Coordinates"><a href="#2-Reconstructing-View-Space-Coordinates" class="headerlink" title="2. Reconstructing View-Space Coordinates:"></a>2. Reconstructing View-Space Coordinates:</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">float3 <span class="title">ComputePositionViewFromZ</span><span class="params">(float2 posNdc, <span class="type">float</span> viewSpaceZ)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    float2 screenSpaceRay = <span class="built_in">float2</span>(</span><br><span class="line">        posNdc.x / -g_transform_cameraToProjected._m00,</span><br><span class="line">        posNdc.y / -g_transform_cameraToProjected._m11</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    float3 posV;</span><br><span class="line">    posV.z = viewSpaceZ;</span><br><span class="line">    posV.xy = screenSpaceRay.xy * posV.z;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> posV;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-Position-Gradients"><a href="#3-Position-Gradients" class="headerlink" title="3. Position Gradients:"></a>3. Position Gradients:</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.posV_DX = <span class="built_in">ComputePositionViewFromZ</span>(posNdcX, viewSpaceZ + rawData.posZGrad.x) - data.posV;</span><br><span class="line">data.posV_DY = <span class="built_in">ComputePositionViewFromZ</span>(posNdcY, viewSpaceZ + rawData.posZGrad.y) - data.posV;</span><br></pre></td></tr></table></figure>
<h3 id="Reconstructing-View-SPace-Normals"><a href="#Reconstructing-View-SPace-Normals" class="headerlink" title="Reconstructing View-SPace Normals"></a>Reconstructing View-SPace Normals</h3><p>The normals are stored in the G-Buffer using a compact <strong>Sphere Map encoding</strong>. This encoding reduces the 3D normal vector into two 2D components while preserving precision.</p>
<p>To reconstruct the 3D normal in shaders, the following decoding function is used:<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">float3 <span class="title">DecodeSphereMap</span><span class="params">(float2 encoded)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    float4 nn = <span class="built_in">float4</span>(encoded, <span class="number">1</span>, <span class="number">-1</span>);</span><br><span class="line">    <span class="type">float</span> l = <span class="built_in">dot</span>(nn.xyz, -nn.xyw);</span><br><span class="line">    nn.z = l;</span><br><span class="line">    nn.xy *= <span class="built_in">sqrt</span>(l);</span><br><span class="line">    <span class="keyword">return</span> nn.xyz * <span class="number">2</span> + <span class="built_in">float3</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">-1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="GPU-Pipeline"><a href="#GPU-Pipeline" class="headerlink" title="GPU Pipeline"></a>GPU Pipeline</h1><h2 id="Over-View"><a href="#Over-View" class="headerlink" title="Over View"></a>Over View</h2><p>On each invocation of pipeline, we send a mesh (a mesh of triangle) to be rendered. This is in the form of vertex and index buffer. And then in the input assembler, assemble this vertex into triangles. In vertex shader, transform these triangles. In the rasterizer, we rasterize these triangles into their pixel representation. In the pixel shader, shade each of these pixels and then hopefully write the result of  the frame buffer.<br>An important thins is the most expensive part of the pipeline is the pixel shader. This is expensive both for memory accesses and for compute, typically we have multiple texture inputs that we sample each one of large textures. As well as combination of these texture samples into final color can be quite computationally expensive. And the particular way in which we combine these samples together is defined by the brdf(bi-directional reflectance distribution function) This essentially defines how light is reflected off an opaque surface. So a particular material will have a particular brdf. Some examples of these are the Phong model, the lambertian model.</p>
<h2 id="Forward-Rendering"><a href="#Forward-Rendering" class="headerlink" title="Forward Rendering"></a>Forward Rendering</h2><h3 id="multi-pass-forward-rendering"><a href="#multi-pass-forward-rendering" class="headerlink" title="multi-pass forward rendering"></a>multi-pass forward rendering</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> mesh in meshes :</span><br><span class="line">    <span class="keyword">for</span> ligth in lights :</span><br><span class="line">        <span class="built_in">draw</span>(mesh, light)</span><br></pre></td></tr></table></figure>
<p>We execute entire pipeline from start to finish in a single pass, once for every mesh light pair. So what we are doing is for each object we are accumulating the effects of each light on it into the framebuffer over multiple draw calls. Draw call is an invocation of the pipeline. We do multiple passes per mesh. We are doing a lot of unnecessary draw calls. Imagine we have a mesh and a light separated by a solid wall. That light contributes nothing to that mesh. However, we are still going to try and draw it anyway</p>
<h3 id="Transparent-Surfaces"><a href="#Transparent-Surfaces" class="headerlink" title="Transparent Surfaces"></a>Transparent Surfaces</h3><p>To render semi-transparent surfaces , we want it to tint what is behind it, we must blend what is behind the surface with the surface itself, in the framebuffer. They must be drawn after opaque surfaces.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ligth in lights :</span><br><span class="line">    <span class="keyword">for</span> mesh in opaqueMeshes :</span><br><span class="line">        <span class="built_in">draw</span>(mesh, light)</span><br><span class="line">    <span class="keyword">for</span> mesh in transparentMeshes :</span><br><span class="line">        <span class="built_in">draw</span>(mesh, light)</span><br></pre></td></tr></table></figure>
<h3 id="Pros-of-Forward-rendering"><a href="#Pros-of-Forward-rendering" class="headerlink" title="Pros of Forward rendering"></a>Pros of Forward rendering</h3><p>Very efficient with few lights<br>We can do transparent surfaces very easily<br>Can models different meshes with <strong>different materials</strong> (BRDFs). We can specialize different materials by having different pixel shaders for each one</p>
<h3 id="Cons-of-Forwartd-rendering"><a href="#Cons-of-Forwartd-rendering" class="headerlink" title="Cons of Forwartd rendering"></a>Cons of Forwartd rendering</h3><p>As we add lights, performance decreases rapidly.<br><em>|draw calls| = |meshes| * |lights|</em><br>This is also has overhead for the CPU. The CPU has to generate these draw calls</p>
<h2 id="Deferred-Rendering"><a href="#Deferred-Rendering" class="headerlink" title="Deferred Rendering"></a>Deferred Rendering</h2><p>Remove the dependence between meshes and lights. </p>
<h3 id="Precompute-Z-Buffer"><a href="#Precompute-Z-Buffer" class="headerlink" title="Precompute Z Buffer"></a>Precompute Z Buffer</h3><p>The many games the z-buffer is pre-computed before the main rendering pass. This is done so to optimize the main rendering pass.</p>
<h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>Same way, we can pre-computation with all the material properties as well as the depth of the pixel, this is the deferred rendering.<br>Split the traditional pipeline into two stages, the first stage is attribute rendering, and the second stage is shading. In a forward renderer in the shading step, typically we read from multiple textures and these samples we take are the material properties at that point on the surface of the mesh. So we might sample from a normal map, we take those samples and we combine them into some final color using the brdf.<br>Instead, let’s directly write those material attributes that we’ve sampled into what’s called a G-buffer, reduced the amount of computation we do. However it is very memory intensive. We still have to sample these large textures.<br>In the second stage, the shading stage. We do texture reads from each of the image in the G-Buffer for each pixel, we can combine these samples using the brdf.<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> mesh in meshes :</span><br><span class="line">    <span class="built_in">drawToGBuffer</span>(mesh)</span><br><span class="line"><span class="keyword">for</span> ligth in lights :</span><br><span class="line">    <span class="built_in">drawToFramebuffer</span>(light)</span><br></pre></td></tr></table></figure><br>In the attribute rendering stage, we don’t have to know about the lights at all. In the shading stage, we are not referencing the meshes at all, we have compressed all the meshes into the single G-Buffer, so we can simply iterate over the lights and compute the contribution of each light to the scene using the information simply in the G-Buffer.<br>There are some downsides to this when we compress the entire scene into this G-buffer, we lose ths ability to keep track of what is behind, this is fine with opaque surfaces we can’t see through them see what is behind, but transparency need us to see behind, so we lose the ability to do transparency. As well as we have this potentially huge G-Buffer, which can really eat up memory bandwidth.</p>
<p>What we are doing is we are deferring the pixel shading until after we have determined which pixel actually have to be shaded, and this minimizes the number of wasted pixel shaders, pixel shading is the most expensive part of this pipeline.</p>
<h3 id="Modifications-to-forward-rendering"><a href="#Modifications-to-forward-rendering" class="headerlink" title="Modifications to forward rendering"></a>Modifications to forward rendering</h3><p>Have the same benefit of minimizing wasted pixel shades without the whole deferring idea.</p>
<h3 id="Implementing-the-Shading-Stage"><a href="#Implementing-the-Shading-Stage" class="headerlink" title="Implementing the Shading Stage"></a>Implementing the Shading Stage</h3><h4 id="We-need-to-Start-from-the-triangle-not-the-G-Buffer-input-old-GPU-not-allow-just-start-from-G-Buffer-must-start-from-triangle-input"><a href="#We-need-to-Start-from-the-triangle-not-the-G-Buffer-input-old-GPU-not-allow-just-start-from-G-Buffer-must-start-from-triangle-input" class="headerlink" title="We need to Start from the triangle, not the G-Buffer input(old GPU not allow just start from G-Buffer, must start from triangle input)"></a>We need to Start from the triangle, not the G-Buffer input(old GPU not allow just start from G-Buffer, must start from triangle input)</h4><p><strong>Render a full-screen quad:</strong><br>Let’s say we have a big light the sun affects the entire screen, we can do is put in a pair of triangles form a quad, this quad fills the entire screen. When we rasterize the quad and do the shading we are essentially doing shading on every single on every single pixel of screen. At each pixel we can sample each of the texture in the G-Buffer that we need to get the material attributes from and then compute the resulting color using the brdf.<br>It works very well if the light fills the entire screen, but when we have a small light, that affect only a small part of the screen. We only have to shader pixels that radius away from the light, this is where triangle fans come in<br><strong>Triangle fans:</strong><br>There triangle fans approximate circles that center only on small lights. When we rasterize these triangle fans, only the pixels that are close enough to the light, to have some significant contribution are going to be shaded. So this is a way to minimize the wasted pixel shades</p>
<div align="center">
  <img src="/images/CG/DeferShadingStage.png" alt="Game Screenshot">
</div>

<h4 id="Pros"><a href="#Pros" class="headerlink" title="Pros"></a>Pros</h4><ul>
<li>Performance scales linearly with #meshes and #lights, we can add more lights</li>
</ul>
<h4 id="Cons"><a href="#Cons" class="headerlink" title="Cons"></a>Cons</h4><ul>
<li>Lose transparent surfaces</li>
<li>Sample A large G-Buffer eats memory bandwidth</li>
<li>Rendering multiple materials become a issue</li>
</ul>
<h3 id="Material"><a href="#Material" class="headerlink" title="Material"></a>Material</h3><p>In deferred rendering, we lose the information of which mesh a particular pixel belongs to. We can’t run different shaders for different meshes. We have to draw the entire scene using the same brdf.<br>But there is a way around this, What we can do is we can assign id to each material, for example a 8-bit number. Then in the first stage, the attribute rendering stage, we can store the id of the material of the mesh we are rendering in the G-Buffer. What we can then do is we can take our all disparate pixel shaders one for each material, we can combine them all into one huge pixel shader. And this shader, at the beginning it samplers for the material id, and branches to the particular brdf. This can be huge it can branch to as many different branches as you have materials.<br>Now the idea of combining all your shaders into one with loads of branches sounds horrific for performance. But it is not that bad, pixels that are spatially local together are very likely to use the same material, so we actually make very strong use of spatial locality. Pixels in the same area are likely ot make the same take the exact same path through the fragment shader.</p>
<h3 id="Transparency-in-some-cases-can-be-done-in-deferred-rendering"><a href="#Transparency-in-some-cases-can-be-done-in-deferred-rendering" class="headerlink" title="Transparency in some cases can be done, in deferred rendering"></a>Transparency in some cases can be done, in deferred rendering</h3><p>Render the entire scene without transparent surfaces using deferred renderer, then takes the transparent surfaces and render those using a separate forward renderer. And it takes the results of those and it actually blends in those rasterized transparent surfaces on top of the frame buffer that we generated before with the deferred renderer</p>
<h3 id="Nowdays"><a href="#Nowdays" class="headerlink" title="Nowdays"></a>Nowdays</h3><p>Advanced and heavy pre-processing of geometry and lights in order to cull geometry and lights we don’t need to draw, this reduces the amount of data being sent to gpu for rendering.<br>The reason this change is because the bottleneck has changed, in the past the bottleneck was throughput and the number of draw calls, nowdays the bottleneck is memory draw call is cheap. We find forward rendering with very heavy pre-processing of the geometry is as fast as deferred rendering</p>
<p>Memory bottleneck means:</p>
<ol>
<li>CPU to GPU bottleneck<br> The data sent from CPU to GPU is typically mesh and texture data<br> Help with this bottleneck:<pre><code> we want to minimize the amount of geometry and textured data being sent over bus. Deferred doesn&#39;t actually help with this because we send every mesh to be rendered with both traditional forward and deferred rendering (Both way need to sent all the mesh and texture). So this is why we do the pre-processing we cull the unnecessary mesh light pairs being drawn, so that we don&#39;t have to send as much over, reduces the load on pcie bus 
</code></pre></li>
<li>GPU internal bottlenech<br> Moving data internally on GPU, for example having a large G-Buffer, we both write to G-Buffer (attribute rendering) and we sample from it, so we convert between those representations that can be quite expensive.<br> Become a issue because we are using larger and larger textures, we really don’t need this huge G-Buffer taking up our quickly diminishing memory bandwidth</li>
</ol>
<p>So a lot of games doing this pre-processing before forward rendering</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://zhangzs11.github.io">Zishuai Zhang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://zhangzs11.github.io/2025/01/20/GraphicsSystem-DeferredRendering/">https://zhangzs11.github.io/2025/01/20/GraphicsSystem-DeferredRendering/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/img/MyAvatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/01/18/GraphicsSystem-FXAA/" title="GraphicsSystem-FXAA"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">GraphicsSystem-FXAA</div></div><div class="info-2"><div class="info-item-1">FXAAThis pixel shader implements Fast Approximate Anti-Aliasing (FXAA), a post-processing technique designed to smooth edges and reduce aliasing in rendered images.This algorithm does not approach the problem from the perspective of geometry or line segments but instead relies solely on the luminance information of the current pixel and its surrounding pixels to detect edges and apply smoothing. Luminance CalculationConvert the pixel’s RGB color into a single luminance value, representing...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/MyAvatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Zishuai Zhang</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">38</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/zhangzs11" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:zhangzs2023@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Deferred-Rendering-G-Buffer-Construction"><span class="toc-number">1.</span> <span class="toc-text">Deferred Rendering: G-Buffer Construction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Vertex-Shader"><span class="toc-number">1.1.</span> <span class="toc-text">Vertex Shader</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pixel-Shader"><span class="toc-number">1.2.</span> <span class="toc-text">Pixel Shader</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Surface-Data-Calculation"><span class="toc-number">1.2.1.</span> <span class="toc-text">Surface Data Calculation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Face-Normal-Calculation"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">Face Normal Calculation</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Normal-Encoding"><span class="toc-number">1.2.2.</span> <span class="toc-text">Normal Encoding</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#G-Buffer-Outputs"><span class="toc-number">1.3.</span> <span class="toc-text">G-Buffer Outputs</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Decoding-G-Buffer-for-Scene-Rendering"><span class="toc-number">2.</span> <span class="toc-text">Decoding G-Buffer for Scene Rendering</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Decoding-the-G-Buffer"><span class="toc-number">2.1.</span> <span class="toc-text">Decoding the G-Buffer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Decoding-Function"><span class="toc-number">2.2.</span> <span class="toc-text">Decoding Function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Reconstructing-View-Space-Position"><span class="toc-number">2.2.1.</span> <span class="toc-text">Reconstructing View-Space Position</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Depth-to-View-Space-Conversion"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">1. Depth to View-Space Conversion :</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-Reconstructing-View-Space-Coordinates"><span class="toc-number">2.2.1.2.</span> <span class="toc-text">2. Reconstructing View-Space Coordinates:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Position-Gradients"><span class="toc-number">2.2.1.3.</span> <span class="toc-text">3. Position Gradients:</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reconstructing-View-SPace-Normals"><span class="toc-number">2.2.2.</span> <span class="toc-text">Reconstructing View-SPace Normals</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GPU-Pipeline"><span class="toc-number">3.</span> <span class="toc-text">GPU Pipeline</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Over-View"><span class="toc-number">3.1.</span> <span class="toc-text">Over View</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Forward-Rendering"><span class="toc-number">3.2.</span> <span class="toc-text">Forward Rendering</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#multi-pass-forward-rendering"><span class="toc-number">3.2.1.</span> <span class="toc-text">multi-pass forward rendering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transparent-Surfaces"><span class="toc-number">3.2.2.</span> <span class="toc-text">Transparent Surfaces</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pros-of-Forward-rendering"><span class="toc-number">3.2.3.</span> <span class="toc-text">Pros of Forward rendering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cons-of-Forwartd-rendering"><span class="toc-number">3.2.4.</span> <span class="toc-text">Cons of Forwartd rendering</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deferred-Rendering"><span class="toc-number">3.3.</span> <span class="toc-text">Deferred Rendering</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Precompute-Z-Buffer"><span class="toc-number">3.3.1.</span> <span class="toc-text">Precompute Z Buffer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pipeline"><span class="toc-number">3.3.2.</span> <span class="toc-text">Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Modifications-to-forward-rendering"><span class="toc-number">3.3.3.</span> <span class="toc-text">Modifications to forward rendering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Implementing-the-Shading-Stage"><span class="toc-number">3.3.4.</span> <span class="toc-text">Implementing the Shading Stage</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#We-need-to-Start-from-the-triangle-not-the-G-Buffer-input-old-GPU-not-allow-just-start-from-G-Buffer-must-start-from-triangle-input"><span class="toc-number">3.3.4.1.</span> <span class="toc-text">We need to Start from the triangle, not the G-Buffer input(old GPU not allow just start from G-Buffer, must start from triangle input)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Pros"><span class="toc-number">3.3.4.2.</span> <span class="toc-text">Pros</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Cons"><span class="toc-number">3.3.4.3.</span> <span class="toc-text">Cons</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Material"><span class="toc-number">3.3.5.</span> <span class="toc-text">Material</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transparency-in-some-cases-can-be-done-in-deferred-rendering"><span class="toc-number">3.3.6.</span> <span class="toc-text">Transparency in some cases can be done, in deferred rendering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Nowdays"><span class="toc-number">3.3.7.</span> <span class="toc-text">Nowdays</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/20/GraphicsSystem-DeferredRendering/" title="GraphicsSystem-Deferred Rendering">GraphicsSystem-Deferred Rendering</a><time datetime="2025-01-20T21:05:08.640Z" title="Created 2025-01-20 14:05:08">2025-01-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/18/GraphicsSystem-FXAA/" title="GraphicsSystem-FXAA">GraphicsSystem-FXAA</a><time datetime="2025-01-19T05:19:14.585Z" title="Created 2025-01-18 22:19:14">2025-01-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/18/GraphicsSystem-NormalMapping/" title="GraphicsSystem-Normal Mapping">GraphicsSystem-Normal Mapping</a><time datetime="2025-01-18T18:19:54.862Z" title="Created 2025-01-18 11:19:54">2025-01-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/18/GraphicsSystem-Skybox/" title="GraphicsSystem-Skybox">GraphicsSystem-Skybox</a><time datetime="2025-01-18T18:19:22.199Z" title="Created 2025-01-18 11:19:22">2025-01-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/16/Graphics_System-Shadow/" title="GraphicsSystem-Shadow Mapping">GraphicsSystem-Shadow Mapping</a><time datetime="2024-12-16T07:00:00.000Z" title="Created 2024-12-16 00:00:00">2024-12-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Zishuai Zhang</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }
      
      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>